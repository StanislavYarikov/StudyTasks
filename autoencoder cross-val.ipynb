{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee676d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557dfebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Qж ТМ, м3/сут', 'Qн, т/сут', 'Qн ТМ, т/сут',\n",
    "                        'ГФ, м3/т', 'ГФ ТМ, м3/т', 'Обв ХАЛ, %', 'Нд, м',\n",
    "                        'Рзатр, атм', 'Dшт, мм', 'КВЧ', 'I, А', 'F, Гц',\n",
    "                        'Рприем, атм', 'Мехпримеси (ХАЛ), мг/дм3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7745eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import pre_process_only_bad\n",
    "from tools import pre_process_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a048999",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_data = pre_process_only_bad(all_paths=pd.read_csv('cooked data\\\\_squajins.csv')['0'].values,\n",
    "                        source='cooked data\\\\',\n",
    "                        num_cols=num_cols)\n",
    "###break_data.to_csv(\"break_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "368c9c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c7c558b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'309': 7,\n",
       "         '1025': 14,\n",
       "         '1023': 14,\n",
       "         '1031': 14,\n",
       "         '1008': 28,\n",
       "         '927': 7,\n",
       "         '624': 28,\n",
       "         '1020': 7,\n",
       "         '1026': 14,\n",
       "         '345': 28,\n",
       "         '331': 7,\n",
       "         '335': 7,\n",
       "         '346': 7,\n",
       "         '634': 28,\n",
       "         '947': 7,\n",
       "         '628': 21,\n",
       "         '946': 7,\n",
       "         '1032': 14,\n",
       "         '1030': 7,\n",
       "         '948': 21,\n",
       "         '953': 14,\n",
       "         '449': 7,\n",
       "         '731': 7,\n",
       "         '452': 14,\n",
       "         '451': 14,\n",
       "         '937': 14,\n",
       "         '936': 14,\n",
       "         '671': 28,\n",
       "         '1103': 14,\n",
       "         '1112': 7,\n",
       "         '1047': 7,\n",
       "         '1113': 7,\n",
       "         '361': 7,\n",
       "         '362': 14,\n",
       "         '372': 21,\n",
       "         '1040': 14,\n",
       "         '137': 7,\n",
       "         '371': 14,\n",
       "         '636': 7,\n",
       "         '635': 7,\n",
       "         '633': 14,\n",
       "         '976': 28,\n",
       "         '977': 14,\n",
       "         '968': 7,\n",
       "         '964': 14,\n",
       "         '957': 14,\n",
       "         '106': 14,\n",
       "         '124': 7,\n",
       "         '301': 7,\n",
       "         '304': 14,\n",
       "         '305': 14,\n",
       "         '319': 7,\n",
       "         '320': 7,\n",
       "         '328': 7,\n",
       "         '329': 14,\n",
       "         '333': 21,\n",
       "         '334': 21,\n",
       "         '467': 7,\n",
       "         '625': 7,\n",
       "         '629': 7,\n",
       "         '723': 7})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(break_data['Скважина'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a631fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#break_data = pd.read_csv(\"break_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df529942",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced, o = pre_process_normal(all_paths=pd.read_csv('cooked data\\\\_squajins.csv')['0'].values,\n",
    "                        source='cooked data\\\\',\n",
    "                        num_cols=num_cols,\n",
    "                        filter_method='delete')\n",
    "#reduced.to_csv('reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba8c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced =  pd.read_csv(\"reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6e1f277f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "66af66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def generate_datasets(data, window_size,scale=True, scaler_type=StandardScaler):\n",
    "    _l = len(data) \n",
    "    data = scaler_type().fit_transform(data)\n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    for i in range(0, (_l - window_size)):\n",
    "        Xs.append(data[i:i+window_size] + np.random.normal(loc=0.0,\n",
    "                                                           scale=0.1,\n",
    "                                                           size=data[i:i+window_size].shape)) \n",
    "        Ys.append(data[i:i+window_size]) \n",
    "\n",
    "    return  Xs, Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e2f2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "86ec1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7cecc090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(true, pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    true = list(true)\n",
    "    pred = list(pred)\n",
    "    \n",
    "    for i in range(len(true)): \n",
    "        if pred[i]==1 and true[i]==pred[i]:\n",
    "            TP += 1\n",
    "        if pred[i]==1 and true[i]!=pred[i]:\n",
    "            FP += 1\n",
    "        if pred[i]==0 and true[i]==pred[i]:\n",
    "            TN += 1\n",
    "        if pred[i]==0 and true[i]!=pred[i]:\n",
    "            FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "def evaluate(true, pred):\n",
    "    print('accuracy_score: ' + str(accuracy_score(true, pred)))\n",
    "    print('precision_score: ' + str(precision_score(true, pred)))\n",
    "    print('recall_score: '+ str(recall_score(true, pred)))\n",
    "    TP, FP, TN, FN = perf_measure(pred, true)\n",
    "    print(perf_measure(true, pred))\n",
    "    print('TruePositive: ' + str(TP) + ' TrueNegative: ' + str(TN))\n",
    "    print('FalsePositive: ' + str(FP) + ' FalseNegative: ' + str(FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dd04a1c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_1 (LSTM)             (None, 7, 64)             20224     \n",
      "_________________________________________________________________\n",
      "encoder_2 (LSTM)             (None, 7, 32)             12416     \n",
      "_________________________________________________________________\n",
      "encoder_3 (LSTM)             (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "encoder_decoder_bridge (Repe (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "decoder_1 (LSTM)             (None, 7, 16)             2112      \n",
      "_________________________________________________________________\n",
      "decoder_2 (LSTM)             (None, 7, 32)             6272      \n",
      "_________________________________________________________________\n",
      "decoder_3 (LSTM)             (None, 7, 64)             24832     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 7, 14)             910       \n",
      "=================================================================\n",
      "Total params: 69,902\n",
      "Trainable params: 69,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "window_length = 7\n",
    "feats = 14\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', min_delta=1e-2, patience=5, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=True)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(64, kernel_initializer='he_uniform', batch_input_shape=(None, window_length, feats), return_sequences=True, name='encoder_1'))\n",
    "model.add(keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='encoder_2'))\n",
    "model.add(keras.layers.LSTM(16, kernel_initializer='he_uniform', return_sequences=False, name='encoder_3'))\n",
    "model.add(keras.layers.RepeatVector(window_length, name='encoder_decoder_bridge'))\n",
    "model.add(keras.layers.LSTM(16, kernel_initializer='he_uniform', return_sequences=True, name='decoder_1'))\n",
    "model.add(keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='decoder_2'))\n",
    "model.add(keras.layers.LSTM(64, kernel_initializer='he_uniform', return_sequences=True, name='decoder_3'))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Dense(feats)))\n",
    "model.compile(loss=\"mse\",optimizer='adam')\n",
    "model.build()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a78934e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 763\n",
      "=========== model 467 fitting =====================\n"
     ]
    }
   ],
   "source": [
    "sqerr1 = []\n",
    "sqerr2 = []\n",
    "persitions = []\n",
    "accuracys = []\n",
    "recalls = []\n",
    "\n",
    "for sq in set(reduced['Скважина']):\n",
    "    curr_test = reduced[reduced['Скважина'] == sq]\n",
    "    curr_train = reduced[reduced['Скважина'] != sq][:10000]\n",
    "    \n",
    "    break_test = break_data[break_data['Скважина'] != sq]\n",
    "    \n",
    "    _, clean_test = generate_datasets(curr_test[num_cols], 7)\n",
    "    noisy_train, clean_train = generate_datasets(curr_train[num_cols], 7)\n",
    "    _, clean_break = generate_datasets(break_test[num_cols], 7)\n",
    "    \n",
    "    print(len(clean_test), len(clean_break))\n",
    "    if len(clean_test) > len(clean_break):\n",
    "        clean_test = clean_test[:len(clean_break)]\n",
    "    else:\n",
    "        clean_break = clean_break[:len(clean_test)]\n",
    "        \n",
    "    if len(clean_test) < 21:\n",
    "        continue\n",
    "    \n",
    "    print('=========== model', sq, \"fitting =====================\")\n",
    "    model.fit(np.stack(noisy_train), np.stack(clean_train), epochs=25, batch_size=32, verbose=0)\n",
    "  \n",
    "    predictions = []\n",
    "    true = []\n",
    "\n",
    "    summ = 0\n",
    "    predicted = model.predict(np.stack(clean_break))\n",
    "    for i in range(len(clean_break)):\n",
    "        true.append(1)\n",
    "        mse = mean_squared_error(clean_break[i], predicted[i])\n",
    "        summ += mse\n",
    "        if mse > 1.47:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "            \n",
    "    res = summ / len(clean_break)\n",
    "    sqerr2.append(res)\n",
    "    print(\"mse break\", res)\n",
    "    \n",
    "    summ = 0\n",
    "    predicted = model.predict(np.stack(clean_test))\n",
    "    for i in range(len(clean_test)):\n",
    "        true.append(0)\n",
    "        mse = mean_squared_error(clean_test[i], predicted[i])\n",
    "        summ += mse\n",
    "        if mse > 1.47:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "            \n",
    "    res = summ / len(clean_test)\n",
    "    sqerr1.append(res)\n",
    "    print(\"mse normal (clean)\", res)  \n",
    "    \n",
    "    evaluate(true, predictions)\n",
    "    \n",
    "    keras.backend.clear_session()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8528dfc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
